---
title: "Clase 5 - Introducción al uso y aplicación de paquetes estadísticos para el tratamiento de fuentes de información en investigación social cuantitativa"
author: "José Rodríguez de la Fuente - Albano Vergara Parra"
institute: "Doctorado en Ciencias Sociales - Universidad de Buenos Aires"
format: 
  html:
    theme: journal
    toc: true
    toc-title: Contenido
    number-sections: true
    embed-resources: true
    smooth-scroll: true
    code-overflow: wrap
    code-copy: hover
    code-tools: false
    code-annotations: hover
lang: es
highlight-style: espresso
lightbox: true
cache: false
execute:
  warning: false
  message: false
---

# Resumen y agregación de datos

Frecuentemente necesitamos resumir la información de muchas observaciones en un único valor. Por ejemplo, si queremos calcular el promedio de edad o de ingresos, o cualquier otra medida de tendencia central, lo que estamos haciendo es resumir la información de una variable en un único valor.

Otras veces, nuestra variable es de tipo categórica y queremos conocer la frecuencia de cada categoría en el total de la población. Es común, a partir de los datos censales o de encuestas de hogares, calcular tasas de actividad, de empleo, de analfabetismo, o razones masculinidad o femineidad, entre otras. En estos casos, previo al conteo de casos, necesitaremos agrupar a la población en las categorías de interés.

Para ello, en este apartado, revisaremos el uso de las funciones `summarise()` y `group_by()` del paquete `dplyr` para resumir y agregar datos.

## Librerías

Para esta clase, necesitaremos tener instaladas las siguientes librerías:

```{r eval=FALSE}
install.packages("summarytools")
install.packages("DescTools")
```

## Base de datos y librerías

Para revisar estas funciones utilizaremos la base de individuos de la *EPH*. Para ello vamos a descargar los datos desde el paquete `eph`. A su vez, seguiremos usando los paquetes del `tidyverse`.

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(eph)

eph_ind <- get_microdata(year = 2024, period = 4, type = "individual")

```

## Uso de ponderadores para las estimaciones  

Generalmente las encuestas de hogares como la *EPH* o el *Latinobarómetro*, al ser relevamientos realizados con muestreos probabilísticos, utilizan ponderadores para corregir el sesgo de la muestra. Es decir, permiten ajustar en los casos en que determinadas poblaciones se encuentran sub-representadas o sobre-representadas en la muestra. Los ponderadores son variables de tipo numéricas que *multiplican* el valor de cada caso para alcanzar una estimación más cercana a la realidad sobre la que se quiere investigar.  

A su vez, en la *EPH*, los ponderadores funcionan también como *factor de expansión*, es decir, no solo corrigen el error de muestreo, sino que también elevan a las estimaciones al universo de estudio. La *EPH* cuenta con cuatro tipos de ponderadores:  

- **PONDERA**: es el ponderador general que se utiliza para la mayoría de las variables.  

- Los ponderadores de ingresos, que corrigen la *no respuesta*:  
  - **PONDII** para el tratamiento del ingreso total individual  
  - **PONDIIO** para el ingreso de la ocupación principal  
  - **PONDIH** para el ingreso total familiar y para el ingreso per cápita familiar  
  
En los siguientes ejemplos que veamos utilizaremos el ponderador adecuado para realizar las estimaciones.  

## Estadísticas resumen

El análisis exploratorio de datos (**EDA** en inglés)  funciona como una primera aproximación a las variables por separado. A la vez, nos sirve para observar si se cumplen determinados supuestos estadísticos.

Podemos clasificar cuatro tipos de estadísticas resumen: las de tendencia central, las de dispersión, las de forma y las de posición. Las primeras nos permiten resumir la información de una variable en un único valor, las segundas nos permiten conocer la variabilidad de los datos, las terceras nos permiten conocer la forma de la distribución de los datos y las últimas nos permiten identificar en que posición se ubican determinados valores de las variables.

![Fuente: Fachelli y López Roldán (2015)](imagenes/estadisticos.png){width="70%"}  


### Medidas de tendencia central

-   **Moda**: valor más frecuente / puede realizarse en cualquier nivel de medición

-   **Mediana**: valor que determina la posición central de la distribución de la variable

    -   Es el valor que divide a la distribución en dos mitades (p50)
    -   Solo interviene el orden de las categorías de las variables. No se ve afectada por los valores extremos
    -   Puede calcularse en variables ordinales y cuantitativas

-   **Media**: promedio aritmético de todos los valores de la variable

    -   Solo aplicable en variables cuantitativas
    -   Es necesaria acompañarla de medidas de dispersión
    -   Puede calcularse también la media ponderada, recortada, geométrica o armónica

![Tipos de curvas de distribución](imagenes/curva.png){width="80%"}

### Medidas de posición

-   **Valores extremos**: mínimo y máximo de una distribución de datos
-   **Cuantiles**: nos proporcionan el valor de una variable que acumula un determinado número de casos.
    -   La mediana es el percentil 50
    -   Los cuantiles más conocidos son los cuartiles (25), quintiles (20) o deciles (10)

![Deciles de ingresos presentados por INDEC](imagenes/deciles.png)

### Medidas de dispersión

Complementan la información de centralidad, dan cuenta del comportamiento de la distribución y permiten observar cuán homogéneos o heterogéneos son los datos.

-   **Rango**: diferencia entre el valor más grande y más pequeño de la distribución
-   **Rango intercuartil**: diferencia entre el tercer cuartil (p75) y el primer cuartil (p25)
-   **Varianza**: evalúa las distancias entre los valores particulares y el valor de la media
-   **Desvío estándar**: es la raíz cuadrada de la varianza. Permite restituir la unidad de medida de la variable
-   **Coeficiente de variación**: cociente entre desviación estándar y la media.
    -   Permite comparar entre distintas distribuciones.
    -   Se presenta en %

### Medidas de forma

-   **Simetría**: mide la simetría de la distribución de los datos
    -   Si es 0, la distribución es simétrica (curva normal)
    -   Si es positiva, la distribución es asimétrica hacia la derecha
    -   Si es negativa, la distribución es asimétrica hacia la izquierda

![Fuente: Fachelli y López Roldán (2015)](imagenes/simetria.png){width="60%"}

-   **Curtosis**: permite observar el grado de apuntalamiento o achatamiento que presenta una distribución respecto a la distribución normal
    -   Si es 0, la distribución es mesocúrtica (curva normal)
    -   Si es positiva, la distribución es leptocúrtica (más puntiaguda)
    -   Si es negativa, la distribución es platicúrtica (más achatada)

![Fuente: Fachelli y López Roldán (2015)](imagenes/curtosis.png){width="60%"}

### Calculando medidas resumen en `R`

`R base` cuenta con una función que nos permite calcular estadísticas resumen de una variable de forma rápida y simple, la función `summary()`. Por ejemplo, si quisiéramos estimar el promedio de edad de la población, y otros estadísticos descriptivos, podríamos hacerlo de la siguiente forma:

```{r}
summary(eph_ind$CH06)
```

De este modo, observamos que la edad promedio es `r round(mean(eph_ind$CH06), digits = 2)`, la mediana es `r median(eph_ind$CH06)` y la edad máxima es `r max(eph_ind$CH06)`.  

El único problema con la función `summary()` es que no nos permite calcular estadísticos ponderados. Sin embargo, existe una librería llamada `summarytools` que nos permite agregar el argumento `weights` para calcular las estadísticas ponderadas. Por ejemplo, si quisiéramos calcular el promedio de edad de la población utilizando el ponderador *PONDERA*, podríamos hacerlo de la siguiente forma utilizando la función `descr()`:  

```{r}
library(summarytools)  

descr(eph_ind$CH06, weights = eph_ind$PONDERA)
```


En `dplyr`, la función `summarise()` nos permite realizar el mismo cálculo de forma más ordenada y clara. Por ejemplo, si quisiéramos calcular el promedio de edad de la población (variable CH06), podríamos hacerlo de la siguiente forma:

```{r}
eph_ind %>%
  summarise(promedio_edad = mean(CH06)) # no ponderado

eph_ind %>%
  summarise(promedio_edad = weighted.mean(CH06, PONDERA)) # ponderado

```

`summarise` acepta toda una serie de estadísticos básicos que pueden utilizar:

-   `mean()`: promedio
-   `weighted.mean()`: promedio ponderado
-   `median()`: mediana
-   `min()`: mínimo
-   `max()`: máximo
-   `sd()`: desviación estándar
-   `var()`: varianza
-   `n()`: número de observaciones
-   `sum()`: suma
-   `first()`: primer valor
-   `last()`: último valor
-   `n_distinct()`: número de valores distintos

```{r}
eph_ind %>%
  summarise(promedio_edad = mean(CH06),
            mediana_edad = median(CH06),
            min_edad = min(CH06),
            max_edad = max(CH06),
            sd_edad = sd(CH06))

```

De este modo, la función `summarise` nos permite calcular múltiples estadísticos de forma rápida y sencilla y nos devuelve un *data frame* con un valor para cada estadístico calculado.  

::: {.callout-tip title="Para revisar"}
La mayoría de los estadísticos descriptivos y de dispersión que nos brinda `Rbase` no nos permite utilizar ponderadores. Por lo tanto, si queremos calcular estadísticos ponderados puntuales debemos utilizar otras librerías. Les recomendamos inspeccionar las librerías `survey` y `DescTools`.
:::


## Agregación de datos {#sec-agregacion}

Otra forma de realizar resúmenes o cálculos sobre las variables es a partir de la información agrupada. Frecuentemente necesitamos que nuestras estadísticas sean calculadas por grupos de edad, sexo, nivel educativo, provincia de residencia, país, etc. Para ello, utilizamos la función `group_by()`, que como su nombre lo indica, nos agrupa la información en base a una variable (o más). En términos de la matriz de datos, lo que hace es cambiar la unidad de análisis: de personas a grupos de edad, por ejemplo.

Si quisiéramos calcular el promedio de edad por sexo (variable *CH04*) podríamos seguir las siguientes instrucciones:

```{r}
eph_ind %>% 
  group_by(CH04) %>% 
  summarise(promedio_edad = weighted.mean(CH06, weights = PONDERA))
```

Fíjense que utilizando los *pipes* es sencillo encadenar cada una de las funciones. Primero agrupamos la información por sexo y luego calculamos el promedio de edad. Observando el libro de códigos, identificamos que 1 es varón y 2 mujer, y que el promedio de edad de los varones es `r round(mean(eph_ind$CH06[eph_ind$CH04 == 1]), digits = 2)` y de las mujeres es `r round(mean(eph_ind$CH06[eph_ind$CH04 == 2]), digits = 2)`.

¿A qué se debe un promedio más alto en las mujeres? Una de las explicaciones es que la esperanza de vida de las mujeres es mayor que la de los varones. ¿Como podríamos estimar esto utilizando las funciones vistas anteriormente? Podríamos acercarnos calculando la edad máxima y el percentil 99 de cada sexo, es decir, el valor que acumula el 99% de las observaciones. Para ello, utilizaremos las funciones `max()` y `quantile()`, respectivamente. El código quedaría de la siguiente forma:

```{r}
eph_ind %>% 
  group_by(CH04) %>% 
  summarise(promedio_edad = weighted.mean(CH06, weights = PONDERA),
            max_edad = max(CH06),
            percentil_99 = quantile(CH06, probs = 0.99))

```

### Replicando algunos indicadores de INDEC

**INDEC** publica informes periódicos con los resultados extraídos de la **EPH** sobre mercado de trabajo, ingresos y pobreza. Vamos a tratar de replicar algunos de los indicadores que brindan los informes de [tasas e indicadores socioeconómicos](https://www.indec.gob.ar/uploads/informesdeprensa/mercado_trabajo_eph_4trim24083C6B9E41.pdf){target="_blank"} y [distribución de ingresos](https://www.indec.gob.ar/uploads/informesdeprensa/ingresos_4trim24D779BFC8BE.pdf){target="_blank"} para practicar el uso de `group_by` y `summarise`.

*Tasa de empleo*: es el porcentaje entre la población ocupada y la población total. Nos basaremos en la variable `ESTADO` que mide la condición de actividad de las personas: ocupado (1), desocupado (2), inactivo (3) y menor de 10 años (4).  

```{r}
eph_ind %>% 
  group_by(ESTADO) %>% # Agrupamos por condición de actividad
  summarise(total = sum(PONDERA)) %>% # Sumamos los casos por condición de actividad
  summarise(tasa_empleo = (total[ESTADO == 1] / sum(total)) * 100) # Calculamos la tasa de empleo
  
```

Fíjense que en este caso, utilizamos dos veces la función `summarise()`. La primera vez para contar la cantidad de personas por condición de actividad y la segunda para calcular la tasa de empleo. A su vez, se han utilizado los corchetes para *filtrar* la fila que debemos utilizar para el cálculo.

**Tasa de desocupación**: es el porcentaje entre la población desocupada y la población económicamente activa. Brinda información sobre la proporción de personas que están demandando trabajo y no lo consiguen.


```{r}
eph_ind %>% 
  group_by(ESTADO) %>% # Agrupamos por condición de actividad
  summarise(total = sum(PONDERA)) %>% # Sumamos los casos por condición de actividad
  summarise(tasa_desoc = (total[ESTADO == 2] / sum(total[ESTADO == 1 | ESTADO == 2])) * 100) # Calculamos la tasa de empleo
```

Ahora bien, vamos a calcular la tasa de desocupación por región geográfica. Para ello, utilizaremos la variable *REGION* en la función `group_by` dos veces. 

```{r}
eph_ind %>% 
  group_by(REGION, ESTADO) %>% # Agrupamos por región y condición de actividad
  summarise(total = sum(PONDERA)) %>% 
  group_by(REGION) %>% 
  summarise(tasa_desoc = (total[ESTADO == 2] / sum(total[ESTADO == 1 | ESTADO == 2])) * 100) # Calculamos la tasa de desocupación
```

Para calcular la tasa al interior de cada región, luego de obtener los totales de ocupados y desocupados, debemos volver a aplicar el `group_by()` para agrupar por región. De este modo, la función `summarise()` calculará la tasa de desocupación para cada región.  

**Deciles de ingresos per cápita familiar**: es una medida de posición que consiste en ordenar a la población por los montos de ingresos de menor a mayor según el ingreso per cápita familiar(variable *IPCF*), para luego agruparlos en subconjuntos que contengan cada uno el 10%.  

Para conocer los valores del IPCF, vamos a utilizar la función `Quantile()` de la librería `DescTools`, que nos permite calcular los cuantiles de una variable con la opción de usar el ponderador. En la opción `probs` especificamos los percentiles que queremos calcular, en este caso del 0 al 1 con un incremento de 0.1, es decir, los deciles. El ponderador, al trabajar con la variable IPCF, será *PONDIH*.  


```{r}
library(DescTools)

eph_ind %>% 
  summarise(deciles_ingresos = Quantile(IPCF, probs = seq(0, 1, 0.1), weights = PONDIH)) # Calculamos los deciles de ingresos per cápita familiar
```

Así el cálculo nos devuelve 11 filas en donde cada una representa el límite inferior y superior de cada decil. Por ejemplo, el decil 1 que agrupa al 10 % de la población con ingresos más bajos, tiene un límite inferior de 0 y un límite superior de **`r format(Quantile(eph_ind$IPCF, probs = 0.1, weights = eph_ind$PONDIH, names = F), scientific = FALSE,  big.mark = ".")`**. Por otro lado, el decil 10 que agrupa al 10 % de la población con ingresos más altos, tiene un límite inferior de **`r format(Quantile(eph_ind$IPCF, probs = 0.9, weights = eph_ind$PONDIH, names = F), scientific = FALSE,  big.mark = ".")`** y un límite superior de **`r format(Quantile(eph_ind$IPCF, probs = 1, weights = eph_ind$PONDIH, names = F), scientific = FALSE,  big.mark = ".")`**.

